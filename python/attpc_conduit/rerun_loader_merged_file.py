import argparse
from pathlib import Path

import rerun as rr  # pip install rerun-sdk
from .core.pad_map import PadMap
from .core.config import Config
from .phase_pointcloud import phase_pointcloud
from .phase_cluster import phase_cluster
from .phase_estimate import phase_estimate
from .core.circle import generate_circle_points
from .plot.histogram import Histogrammer
import h5py as h5
import numpy as np

RADIUS = 2.0

grammer = Histogrammer()

grammer.add_2D("pid", 0.0, 5.0e3, 512, "dE/dx", 0.0, 3.0, 512, "Brho(Tm)")
grammer.add_2D("kinematics", 0.0, 180.0, 180, "Polar(deg)", 0.0, 3.0, 512, "Brho(Tm)")
grammer.add_1D("polar", 0.0, 180.0, 180, "polar(deg)")

# The Rerun Viewer will always pass these two pieces of information:
# 1. The path to be loaded, as a positional arg.
# 2. A shared recording ID, via the `--recording-id` flag.
#
# It is up to you whether you make use of that shared recording ID or not.
# If you use it, the data will end up in the same recording as all other plugins interested in
# that file, otherwise you can just create a dedicated recording for it. Or both.
parser = argparse.ArgumentParser(
    description="""
This is an example executable data-loader plugin for the Rerun Viewer.
Any executable on your `$PATH` with a name that starts with `rerun-loader-` will be
treated as an external data-loader.

This particular one will read and analyze AT-TPC HDF5 files generated by the attpc_merger.
"""
)
parser.add_argument("filepath", type=str)
parser.add_argument("--recording-id", type=str)
args = parser.parse_args()


def get_event_range(trace_file: h5.File) -> tuple[int, int]:
    """
    The merger doesn't use attributes for legacy reasons, so everything is stored in datasets. Use this to retrieve the min and max event numbers.

    Parameters
    ----------
    trace_file: h5py.File
        File handle to a hdf5 file with AT-TPC traces

    Returns
    -------
    tuple[int, int]
        A pair of integers (first event number, last event number)
    """
    try:
        meta_group = trace_file["meta"]
        if not isinstance(meta_group, h5.Group):
            return (0, 0)
        meta_data = meta_group["meta"]
        if not isinstance(meta_data, h5.Dataset):
            return (0, 0)
        return (int(meta_data[0]), int(meta_data[2]))
    except Exception:
        return (0, 0)


def main() -> None:
    print("here!")
    config = Config(Path("config.json"))
    pad_map = PadMap()

    path = Path(args.filepath)
    if not path.exists() or not path.is_file() or path.suffix != ".h5":
        print(f"here {path} {path.suffix}")
        exit(
            rr.EXTERNAL_DATA_LOADER_INCOMPATIBLE_EXIT_CODE
        )  # Indicates to Rerun that this file was not handled by this loader
    file = h5.File(path)
    get_group = None
    try:
        get_group = file["get"]
    except Exception:
        file.close()
        exit(rr.EXTERNAL_DATA_LOADER_INCOMPATIBLE_EXIT_CODE)
    if not isinstance(get_group, h5.Group):
        file.close()
        exit(rr.EXTERNAL_DATA_LOADER_INCOMPATIBLE_EXIT_CODE)
    min_event, max_event = get_event_range(file)
    if min_event == 0 and max_event == 0:
        file.close()
        exit(rr.EXTERNAL_DATA_LOADER_INCOMPATIBLE_EXIT_CODE)

    rr.init("attpc_h5_data", recording_id=args.recording_id)
    rr.stdout()

    print("here")
    # log the pad plane bounds
    plane = generate_circle_points(0.0, 0.0, 300.0)
    rr.log("Detector2D/bounds", rr.LineStrips2D(plane), timeless=True)
    # log the coordinate orientation for 3D
    rr.log("Detector3D/", rr.ViewCoordinates.RIGHT_HAND_X_UP, timeless=True)
    # log the detector box
    rr.log(
        "Detector3D/detector_box",
        rr.Boxes3D(half_sizes=[300.0, 300.0, 500.0], centers=[0.0, 0.0, 500.0]),
        timeless=True,
    )

    for event_id in range(min_event, max_event):
        event_data = None
        try:
            event_data = get_group[f"evt{event_id}_data"]
        except Exception:
            continue

        if not isinstance(event_data, h5.Dataset):
            continue

        rr.set_time_sequence("event_time", event_id)
        rr.log("Detector3D/cloud", rr.Clear(recursive=True))
        rr.log("Detector2D/pad_plane", rr.Clear(recursive=True))

        pc = phase_pointcloud(
            event_id, event_data[:].copy(), pad_map, config.get, config.detector
        )
        radii = np.full(len(pc.cloud), RADIUS)
        rr.log(
            f"Detector3D/cloud/point_cloud",
            rr.Points3D(pc.cloud[:, :3], radii=radii),
        )
        rr.log(
            f"Detector2D/pad_plane/raw_plane",
            rr.Points2D(pc.cloud[:, :2], radii=radii),
        )
        clusters = phase_cluster(pc, config.cluster)
        if clusters is not None:
            estimates = phase_estimate(clusters, config.estimate, config.detector)

            for idx, cluster in enumerate(clusters):
                radii = np.full(len(cluster.data), RADIUS)
                rr.log(
                    f"Detector3D/cloud/cluster_{cluster.label}",
                    rr.Points3D(cluster.data[:, :3], radii=radii),
                )
                rr.log(
                    f"Detector2D/pad_plane/cluster_{cluster.label}",
                    rr.Points2D(cluster.data[:, :2], radii=radii),
                )
                est = estimates[idx]
                if est.failed == False:
                    rr.log(
                        f"Detector3D/cloud/cluster_{cluster.label}/vertex",
                        rr.Points3D(est.vertex, radii=[RADIUS]),
                    )
                    rho = est.brho / config.detector.magnetic_field * 1000.0
                    circle = generate_circle_points(est.center[0], est.center[1], rho)
                    radii = np.full(len(circle), RADIUS)
                    rr.log(
                        f"Detector2D/pad_plane/cluster_{cluster.label}/circle",
                        rr.Points2D(circle, radii=radii),
                    )
                    grammer.fill_2D("pid", est.dEdx, est.brho)
                    grammer.fill_2D("kinematics", np.rad2deg(est.polar), est.brho)
                    grammer.fill_1D("polar", np.rad2deg(est.polar))

                    for gram in grammer.grams_1d.values():
                        rr.log(
                            f"Histograms/{gram.name}",
                            rr.BarChart(gram.counts),
                        )

                    for gram in grammer.grams_2d.values():
                        rr.log(
                            f"Histograms/{gram.name}",
                            rr.Tensor(
                                gram.counts,
                                dim_names=(gram.x_axis_title, gram.y_axis_title),
                            ),
                        )
